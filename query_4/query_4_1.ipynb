{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c33366d7-2873-4089-9ce2-ffc49d5cf21b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '2', 'spark.executor.memory': '2g', 'spark.executor.cores': '1'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>944</td><td>application_1765289937462_0937</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0937/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-61.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0937_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>952</td><td>application_1765289937462_0945</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0945/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-55.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0945_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>956</td><td>application_1765289937462_0949</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0949/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-149.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0949_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>960</td><td>application_1765289937462_0953</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0953/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-48.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0953_01_000001/livy\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\":{\n",
    "        \"spark.executor.instances\": \"2\",\n",
    "        \"spark.executor.memory\": \"2g\",\n",
    "        \"spark.executor.cores\": \"1\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "545560c8-098b-4583-b69f-5cfed593e658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>961</td><td>application_1765289937462_0954</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0954/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-103.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0954_01_000002/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291a2136ec3f4f3abb58247b090b9f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b371a5c072a4878887fc7423859bc9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sedona.spark import *\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, FloatType, StringType\n",
    "from pyspark.sql.functions import udf, year, avg, count, concat, lit, round, rank, col\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"query 4 execution\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Create sedona context\n",
    "sedona = SedonaContext.create(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eded49d-c7ea-4d87-a243-bb8892ed3913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833a14d017914c28af498aa80712419a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "crime_df1 = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv\", header = True, inferSchema = True)\n",
    "crime_df2 = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\", header = True, inferSchema = True)\n",
    "crime_df = crime_df1.union(crime_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40caadd5-912b-49b7-945e-e7243517625c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ade92e7d27b4d328501f848349af9ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(X=-118.289241553, Y=33.7576608970001, FID=1, DIVISION='HARBOR', LOCATION='2175 JOHN S. GIBSON BLVD.', PREC=5)"
     ]
    }
   ],
   "source": [
    "stations_df = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Police_Stations.csv\", header = True, inferSchema = True)\n",
    "stations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71f795a9-87f8-4fef-baae-93f2d88d3224",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8264f65ec6d4ab5aea08cc2bf963c2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Window: nearest station per crime\n",
    "window = Window.partitionBy(\"DR_NO\").orderBy(\"distance\")\n",
    "\n",
    "# Filter crimes (drop Null Island etc.)\n",
    "filtered_crimes_df = (\n",
    "    crime_df\n",
    "    .filter(col(\"LAT\").isNotNull() & col(\"LON\").isNotNull())\n",
    "    .filter(~((col(\"LAT\") == 0) & (col(\"LON\") == 0)))   # Null Island\n",
    "    .select(\"DR_NO\", \"LAT\", \"LON\")\n",
    ")\n",
    "# define function for counting distance with sedona\n",
    "def get_distance(lat1_col, lon1_col, lat2_col, lon2_col):\n",
    "    p1 = ST_Point(lon1_col.cast(\"double\"), lat1_col.cast(\"double\"))\n",
    "    p2 = ST_Point(lon2_col.cast(\"double\"), lat2_col.cast(\"double\"))\n",
    "    return ST_DistanceSphere(p1, p2) / 1000.0  # km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2403b1f-95e5-45e8-999b-32547cda2a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52cfc8a8733545ab803eba72d527a2b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------+------+\n",
      "|division        |average_distance_km|#     |\n",
      "+----------------+-------------------+------+\n",
      "|HOLLYWOOD       |2.077              |225515|\n",
      "|VAN NUYS        |2.953              |211130|\n",
      "|SOUTHWEST       |2.191              |189565|\n",
      "|WILSHIRE        |2.593              |187061|\n",
      "|77TH STREET     |1.717              |172558|\n",
      "|OLYMPIC         |1.725              |172353|\n",
      "|NORTH HOLLYWOOD |2.643              |168655|\n",
      "|PACIFIC         |3.853              |162514|\n",
      "|CENTRAL         |0.993              |154952|\n",
      "|SOUTHEAST       |2.422              |153746|\n",
      "|RAMPART         |1.535              |153690|\n",
      "|TOPANGA         |3.298              |141070|\n",
      "|WEST VALLEY     |3.039              |139820|\n",
      "|FOOTHILL        |4.251              |135381|\n",
      "|HARBOR          |3.702              |127370|\n",
      "|HOLLENBECK      |2.677              |116558|\n",
      "|WEST LOS ANGELES|2.79               |116308|\n",
      "|NEWTON          |1.635              |111628|\n",
      "|NORTHEAST       |3.623              |108549|\n",
      "|MISSION         |3.685              |105331|\n",
      "|DEVONSHIRE      |2.824              |81226 |\n",
      "+----------------+-------------------+------+\n",
      "\n",
      "Execution time: 38.64295053482056 seconds"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "# Cross join with stations, compute distance to each station seperately\n",
    "crimes_stations_dist_df = (\n",
    "    filtered_crimes_df\n",
    "    .crossJoin(\n",
    "        stations_df.select(\n",
    "            col(\"division\"),  \n",
    "            col(\"Y\"), # Lat\n",
    "            col(\"X\") # lon\n",
    "        )\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"distance\",\n",
    "        get_distance(col(\"LAT\"), col(\"LON\"), col(\"Y\"), col(\"X\"))\n",
    "    )\n",
    ")\n",
    "\n",
    "# Keep only nearest station per crime\n",
    "nearest_station_df = (\n",
    "    crimes_stations_dist_df\n",
    "    .withColumn(\"distance_rank\", rank().over(window))\n",
    "    .filter(col(\"distance_rank\") == 1) #nearest\n",
    "    .select(\"division\", \"distance\")\n",
    ")\n",
    "\n",
    "# Aggregate per division: count + average distance, sort by count desc\n",
    "division_stats_df = (\n",
    "    nearest_station_df\n",
    "    .groupBy(\"division\")\n",
    "    .agg(\n",
    "        avg(\"distance\").alias(\"average_distance_km\"), \n",
    "        count(\"*\").alias(\"#\") # only for output consistency\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"average_distance_km\",\n",
    "        round(col(\"average_distance_km\"), 3) #round to 3 decimal\n",
    "    )\n",
    "    .orderBy(col(\"#\").desc())\n",
    ")\n",
    "\n",
    "division_stats_df.show(100, truncate=False)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end - start, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34d42e83-c0b3-4395-ab47-7397aab3bc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b62b109096d4bf6af871d5657ea1fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [##281L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(##281L DESC NULLS LAST, 1000), ENSURE_REQUIREMENTS, [plan_id=585]\n",
      "      +- HashAggregate(keys=[division#221], functions=[avg(distance#249), count(1)], schema specialized)\n",
      "         +- Exchange hashpartitioning(division#221, 1000), ENSURE_REQUIREMENTS, [plan_id=582]\n",
      "            +- HashAggregate(keys=[division#221], functions=[partial_avg(distance#249), partial_count(1)], schema specialized)\n",
      "               +- Project [division#221, distance#249]\n",
      "                  +- Filter (distance_rank#259 = 1)\n",
      "                     +- Window [rank(distance#249) windowspecdefinition(DR_NO#42, distance#249 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS distance_rank#259], [DR_NO#42], [distance#249 ASC NULLS FIRST]\n",
      "                        +- WindowGroupLimit [DR_NO#42], [distance#249 ASC NULLS FIRST], rank(distance#249), 1, Final\n",
      "                           +- Sort [DR_NO#42 ASC NULLS FIRST, distance#249 ASC NULLS FIRST], false, 0\n",
      "                              +- Exchange hashpartitioning(DR_NO#42, 1000), ENSURE_REQUIREMENTS, [plan_id=574]\n",
      "                                 +- WindowGroupLimit [DR_NO#42], [distance#249 ASC NULLS FIRST], rank(distance#249), 1, Partial\n",
      "                                    +- Sort [DR_NO#42 ASC NULLS FIRST, distance#249 ASC NULLS FIRST], false, 0\n",
      "                                       +- Project [DR_NO#42, division#221, ( **org.apache.spark.sql.sedona_sql.expressions.ST_DistanceSphere**   / 1000.0) AS distance#249]\n",
      "                                          +- BroadcastNestedLoopJoin BuildRight, Cross\n",
      "                                             :- Union\n",
      "                                             :  :- Filter ((isnotnull(LAT#68) AND isnotnull(LON#69)) AND (NOT (LAT#68 = 0.0) OR NOT (LON#69 = 0.0)))\n",
      "                                             :  :  +- FileScan csv [DR_NO#42,LAT#68,LON#69] Batched: false, DataFilters: [isnotnull(LAT#68), isnotnull(LON#69), (NOT (LAT#68 = 0.0) OR NOT (LON#69 = 0.0))], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(LAT), IsNotNull(LON), Or(Not(EqualTo(LAT,0.0)),Not(EqualTo(LON,0.0)))], ReadSchema: struct<DR_NO:int,LAT:double,LON:double>\n",
      "                                             :  +- Filter ((isnotnull(LAT#142) AND isnotnull(LON#143)) AND (NOT (LAT#142 = 0.0) OR NOT (LON#143 = 0.0)))\n",
      "                                             :     +- FileScan csv [DR_NO#116,LAT#142,LON#143] Batched: false, DataFilters: [isnotnull(LAT#142), isnotnull(LON#143), (NOT (LAT#142 = 0.0) OR NOT (LON#143 = 0.0))], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(LAT), IsNotNull(LON), Or(Not(EqualTo(LAT,0.0)),Not(EqualTo(LON,0.0)))], ReadSchema: struct<DR_NO:int,LAT:double,LON:double>\n",
      "                                             +- BroadcastExchange IdentityBroadcastMode, [plan_id=567]\n",
      "                                                +- FileScan csv [X#218,Y#219,DIVISION#221] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_P..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<X:double,Y:double,DIVISION:string>"
     ]
    }
   ],
   "source": [
    "division_stats_df.explain()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
