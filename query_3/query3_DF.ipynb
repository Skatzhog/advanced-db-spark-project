{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31d0d797-6b27-45f9-8611-2242f1338070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '4', 'spark.executor.memory': '2g', 'spark.executor.cores': '1'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>10</td><td>application_1765289937462_0011</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0011/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-141.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0011_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>11</td><td>application_1765289937462_0012</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0012/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-103.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0012_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>15</td><td>application_1765289937462_0016</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0016/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-91.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0016_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>16</td><td>application_1765289937462_0017</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0017/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-250.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0017_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>17</td><td>application_1765289937462_0018</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0018/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-250.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0018_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>18</td><td>application_1765289937462_0019</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0019/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-149.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0019_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>20</td><td>application_1765289937462_0021</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0021/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-213.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0021_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>22</td><td>application_1765289937462_0023</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0023/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-207.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0023_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>23</td><td>None</td><td>pyspark</td><td>starting</td><td></td><td></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\":{\n",
    "        \"spark.executor.instances\": \"4\",\n",
    "        \"spark.executor.memory\": \"2g\",\n",
    "        \"spark.executor.cores\": \"1\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36d5d933-f0dc-44b0-ae4e-cd3890a23eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>24</td><td>application_1765289937462_0025</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0025/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-55.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0025_01_000002/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5523de91c0941ada65c1e1152e7481b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44e7519fe3384861a78ebfe06e218ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, FloatType, StringType\n",
    "from pyspark.sql.functions import col  #import needed functions\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"DF query 3 execution\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "crime_schema = StructType([\n",
    "        StructField(\"DR_NO\", StringType()),\n",
    "        StructField(\"Date Rptd\", StringType()),\n",
    "        StructField(\"DATE OCC\", StringType()),\n",
    "        StructField(\"TIME OCC\", StringType()),\n",
    "        StructField(\"AREA\", StringType()),\n",
    "        StructField(\"AREA ΝΑΜΕ\", StringType()),\n",
    "        StructField(\"Rpt Dist No\", StringType()),\n",
    "        StructField(\"Part 1-2\", StringType()),\n",
    "        StructField(\"Crm Cd\", StringType()),\n",
    "        StructField(\"Crm Cd Desc\", StringType()),\n",
    "        StructField(\"Mocodes\", StringType()),\n",
    "        StructField(\"Vict Age\", IntegerType()),\n",
    "        StructField(\"Vict Sex\", StringType()),\n",
    "        StructField(\"Vict Descent\", StringType()),\n",
    "        StructField(\"Premis Cd\", StringType()),\n",
    "        StructField(\"Premis Desc\", StringType()),\n",
    "        StructField(\"Weapon Used Cd\", StringType()),\n",
    "        StructField(\"Weapon Desc\", StringType()),\n",
    "        StructField(\"Status\", StringType()),\n",
    "        StructField(\"Status Desc\", StringType()),\n",
    "        StructField(\"Crm Cd 1\", StringType()),\n",
    "        StructField(\"Crm Cd 2\", StringType()),\n",
    "        StructField(\"Crm Cd 3\", StringType()),\n",
    "        StructField(\"Crm Cd 4\", StringType()),\n",
    "        StructField(\"LOCATION\", StringType()),\n",
    "        StructField(\"Cross Street\", StringType()),\n",
    "        #StructField(\"LAT\", DoubleType()),\n",
    "        #StructField(\"LON\", DoubleType()),\n",
    "    ])\n",
    "\n",
    "crime_df1 = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv\", \\\n",
    "    header=False, \\\n",
    "    schema=crime_schema)\n",
    "\n",
    "crime_df2 = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\", \\\n",
    "    header=False, \\\n",
    "    schema=crime_schema)\n",
    "\n",
    "# make a single dataframe for crime data from 2010 to present\n",
    "crime_df = crime_df1.union(crime_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d83122be-6271-4740-ab56-3ce6fae4e26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e1aed28f42483f983938d83e2f6977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|MO_CODE|            MO_DESC|\n",
      "+-------+-------------------+\n",
      "|   0100|Suspect Impersonate|\n",
      "|   0101|         Aid victim|\n",
      "|   0102|              Blind|\n",
      "|   0103|Physically disabled|\n",
      "|   0104|           Customer|\n",
      "|   0105|           Delivery|\n",
      "|   0106|             Doctor|\n",
      "|   0107|                God|\n",
      "|   0108|             Infirm|\n",
      "|   0109|          Inspector|\n",
      "+-------+-------------------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, split, explode, trim, desc\n",
    "\n",
    "# raw text file: one line per code\n",
    "raw_mo = spark.read.text(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/MO_codes.txt\"\n",
    ")\n",
    "\n",
    "# assuming: \"<code> <spaces or tab> <description...>\"\n",
    "mo_dict_df = (\n",
    "    raw_mo\n",
    "    .select(\n",
    "        trim(split(col(\"value\"), r\"\\s+\", 2).getItem(0)).alias(\"MO_CODE\"),\n",
    "        trim(split(col(\"value\"), r\"\\s+\", 2).getItem(1)).alias(\"MO_DESC\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# # If it's \"code<TAB>description\"\n",
    "# mo_dict_df = (\n",
    "#     raw_mo\n",
    "#     .select(\n",
    "#         trim(split(col(\"value\"), r\"\\t\", 2).getItem(0)).alias(\"MO_CODE\"),\n",
    "#         trim(split(col(\"value\"), r\"\\t\", 2).getItem(1)).alias(\"MO_DESC\")\n",
    "#     )\n",
    "# )\n",
    "mo_dict_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fbd36f0-9647-49cb-b3b0-3ec4d0f581b9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0165ac5dcf4985a1f2d5a63b4d9fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------------------------+\n",
      "|MO_CODE|count  |MO_DESC                    |\n",
      "+-------+-------+---------------------------+\n",
      "|0344   |1002900|Removes vict property      |\n",
      "|1822   |548422 |Stranger                   |\n",
      "|0416   |404773 |Hit-Hit w/ weapon          |\n",
      "|0329   |377536 |Vandalized                 |\n",
      "|0913   |278618 |Victim knew Suspect        |\n",
      "|2000   |256188 |Domestic violence          |\n",
      "|1300   |219082 |Vehicle involved           |\n",
      "|0400   |213165 |Force used                 |\n",
      "|1402   |177470 |Evidence Booked (any crime)|\n",
      "|1609   |131229 |Smashed                    |\n",
      "+-------+-------+---------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [count#985L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(count#985L DESC NULLS LAST, 1000), ENSURE_REQUIREMENTS, [plan_id=3632]\n",
      "      +- Project [MO_CODE#981, count#985L, MO_DESC#144]\n",
      "         +- BroadcastHashJoin [MO_CODE#981], [MO_CODE#143], LeftOuter, BuildRight, false\n",
      "            :- HashAggregate(keys=[MO_CODE#981], functions=[count(1)], schema specialized)\n",
      "            :  +- Exchange hashpartitioning(MO_CODE#981, 1000), ENSURE_REQUIREMENTS, [plan_id=3625]\n",
      "            :     +- HashAggregate(keys=[MO_CODE#981], functions=[partial_count(1)], schema specialized)\n",
      "            :        +- Filter NOT (MO_CODE#981 = )\n",
      "            :           +- Generate explode(split(trim(Mocodes#10, None), \\s+, -1)), false, [MO_CODE#981]\n",
      "            :              +- Union\n",
      "            :                 :- Filter isnotnull(Mocodes#10)\n",
      "            :                 :  +- FileScan csv [Mocodes#10] Batched: false, DataFilters: [isnotnull(Mocodes#10)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(Mocodes)], ReadSchema: struct<Mocodes:string>\n",
      "            :                 +- Filter isnotnull(Mocodes#73)\n",
      "            :                    +- FileScan csv [Mocodes#73] Batched: false, DataFilters: [isnotnull(Mocodes#73)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(Mocodes)], ReadSchema: struct<Mocodes:string>\n",
      "            +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=3628]\n",
      "               +- Project [trim(split(value#141, \\s+, 2)[0], None) AS MO_CODE#143, trim(split(value#141, \\s+, 2)[1], None) AS MO_DESC#144]\n",
      "                  +- Filter (NOT (trim(split(value#141, \\s+, 2)[0], None) = ) AND isnotnull(trim(split(value#141, \\s+, 2)[0], None)))\n",
      "                     +- FileScan text [value#141] Batched: false, DataFilters: [NOT (trim(split(value#141, \\s+, 2)[0], None) = ), isnotnull(trim(split(value#141, \\s+, 2)[0], No..., Format: Text, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/MO_c..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      "\n",
      "\n",
      "Execution time: 9.917678117752075 seconds"
     ]
    }
   ],
   "source": [
    "# Optional but useful for determinism: turn off AQE, otherwise Spark may change strategy at runtime\n",
    "# spark.conf.set(\"spark.sql.adaptive.enabled\", \"false\")\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "# 1) Keep rows with non-null Mocodes\n",
    "mocodes_exploded = (\n",
    "    crime_df\n",
    "    .filter(col(\"Mocodes\").isNotNull())\n",
    "    .select(\n",
    "        explode(\n",
    "            split(trim(col(\"Mocodes\")), r\"\\s+\")  # split on 1+ spaces\n",
    "        ).alias(\"MO_CODE\")\n",
    "    )\n",
    "    .filter(col(\"MO_CODE\") != \"\")  # drop empty pieces\n",
    ")\n",
    "\n",
    "mo_counts = (\n",
    "    mocodes_exploded\n",
    "    .groupBy(\"MO_CODE\")\n",
    "    .count()\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "result = (\n",
    "    mo_counts\n",
    "    .join(mo_dict_df, on=\"MO_CODE\", how=\"left\")\n",
    "    .orderBy(desc(\"count\"))\n",
    ")\n",
    "\n",
    "result.show(10, truncate=False)\n",
    "result.explain()\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end - start, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eeea34a-5ef0-4ccf-ada5-22a44aa557e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ea440efcce4c92a8fd9365950b320e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------------------------+\n",
      "|MO_CODE|count  |MO_DESC                    |\n",
      "+-------+-------+---------------------------+\n",
      "|0344   |1002900|Removes vict property      |\n",
      "|1822   |548422 |Stranger                   |\n",
      "|0416   |404773 |Hit-Hit w/ weapon          |\n",
      "|0329   |377536 |Vandalized                 |\n",
      "|0913   |278618 |Victim knew Suspect        |\n",
      "|2000   |256188 |Domestic violence          |\n",
      "|1300   |219082 |Vehicle involved           |\n",
      "|0400   |213165 |Force used                 |\n",
      "|1402   |177470 |Evidence Booked (any crime)|\n",
      "|1609   |131229 |Smashed                    |\n",
      "+-------+-------+---------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [count#615L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(count#615L DESC NULLS LAST, 1000), ENSURE_REQUIREMENTS, [plan_id=2352]\n",
      "      +- Project [MO_CODE#611, count#615L, MO_DESC#144]\n",
      "         +- BroadcastHashJoin [MO_CODE#611], [MO_CODE#143], LeftOuter, BuildRight, false\n",
      "            :- HashAggregate(keys=[MO_CODE#611], functions=[count(1)], schema specialized)\n",
      "            :  +- Exchange hashpartitioning(MO_CODE#611, 1000), ENSURE_REQUIREMENTS, [plan_id=2345]\n",
      "            :     +- HashAggregate(keys=[MO_CODE#611], functions=[partial_count(1)], schema specialized)\n",
      "            :        +- Filter NOT (MO_CODE#611 = )\n",
      "            :           +- Generate explode(split(trim(Mocodes#10, None), \\s+, -1)), false, [MO_CODE#611]\n",
      "            :              +- Union\n",
      "            :                 :- Filter isnotnull(Mocodes#10)\n",
      "            :                 :  +- FileScan csv [Mocodes#10] Batched: false, DataFilters: [isnotnull(Mocodes#10)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(Mocodes)], ReadSchema: struct<Mocodes:string>\n",
      "            :                 +- Filter isnotnull(Mocodes#73)\n",
      "            :                    +- FileScan csv [Mocodes#73] Batched: false, DataFilters: [isnotnull(Mocodes#73)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(Mocodes)], ReadSchema: struct<Mocodes:string>\n",
      "            +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=2348]\n",
      "               +- Project [trim(split(value#141, \\s+, 2)[0], None) AS MO_CODE#143, trim(split(value#141, \\s+, 2)[1], None) AS MO_DESC#144]\n",
      "                  +- Filter (NOT (trim(split(value#141, \\s+, 2)[0], None) = ) AND isnotnull(trim(split(value#141, \\s+, 2)[0], None)))\n",
      "                     +- FileScan text [value#141] Batched: false, DataFilters: [NOT (trim(split(value#141, \\s+, 2)[0], None) = ), isnotnull(trim(split(value#141, \\s+, 2)[0], No..., Format: Text, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/MO_c..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      "\n",
      "\n",
      "Execution time: 4.63615870475769 seconds"
     ]
    }
   ],
   "source": [
    "# Note that hints are advisory (Spark may ignore them in pathological cases) and AQE can override them unless disabled.\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "result_broadcast = (\n",
    "    mo_counts\n",
    "    .join(\n",
    "        mo_dict_df.hint(\"broadcast\"),   # or .hint(\"BROADCAST\")\n",
    "        on=\"MO_CODE\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .orderBy(desc(\"count\"))\n",
    ")\n",
    "\n",
    "result_broadcast.show(10, truncate=False)\n",
    "result_broadcast.explain()\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a1a84cc-897a-4607-a268-e63c76444594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73815186eac148069859942b2ec8f0bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------------------------+\n",
      "|MO_CODE|count  |MO_DESC                    |\n",
      "+-------+-------+---------------------------+\n",
      "|0344   |1002900|Removes vict property      |\n",
      "|1822   |548422 |Stranger                   |\n",
      "|0416   |404773 |Hit-Hit w/ weapon          |\n",
      "|0329   |377536 |Vandalized                 |\n",
      "|0913   |278618 |Victim knew Suspect        |\n",
      "|2000   |256188 |Domestic violence          |\n",
      "|1300   |219082 |Vehicle involved           |\n",
      "|0400   |213165 |Force used                 |\n",
      "|1402   |177470 |Evidence Booked (any crime)|\n",
      "|1609   |131229 |Smashed                    |\n",
      "+-------+-------+---------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [count#615L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(count#615L DESC NULLS LAST, 1000), ENSURE_REQUIREMENTS, [plan_id=2706]\n",
      "      +- Project [MO_CODE#611, count#615L, MO_DESC#144]\n",
      "         +- SortMergeJoin [MO_CODE#611], [MO_CODE#143], LeftOuter\n",
      "            :- Sort [MO_CODE#611 ASC NULLS FIRST], false, 0\n",
      "            :  +- HashAggregate(keys=[MO_CODE#611], functions=[count(1)], schema specialized)\n",
      "            :     +- Exchange hashpartitioning(MO_CODE#611, 1000), ENSURE_REQUIREMENTS, [plan_id=2696]\n",
      "            :        +- HashAggregate(keys=[MO_CODE#611], functions=[partial_count(1)], schema specialized)\n",
      "            :           +- Filter NOT (MO_CODE#611 = )\n",
      "            :              +- Generate explode(split(trim(Mocodes#10, None), \\s+, -1)), false, [MO_CODE#611]\n",
      "            :                 +- Union\n",
      "            :                    :- Filter isnotnull(Mocodes#10)\n",
      "            :                    :  +- FileScan csv [Mocodes#10] Batched: false, DataFilters: [isnotnull(Mocodes#10)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(Mocodes)], ReadSchema: struct<Mocodes:string>\n",
      "            :                    +- Filter isnotnull(Mocodes#73)\n",
      "            :                       +- FileScan csv [Mocodes#73] Batched: false, DataFilters: [isnotnull(Mocodes#73)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(Mocodes)], ReadSchema: struct<Mocodes:string>\n",
      "            +- Sort [MO_CODE#143 ASC NULLS FIRST], false, 0\n",
      "               +- Exchange hashpartitioning(MO_CODE#143, 1000), ENSURE_REQUIREMENTS, [plan_id=2700]\n",
      "                  +- Project [trim(split(value#141, \\s+, 2)[0], None) AS MO_CODE#143, trim(split(value#141, \\s+, 2)[1], None) AS MO_DESC#144]\n",
      "                     +- Filter (NOT (trim(split(value#141, \\s+, 2)[0], None) = ) AND isnotnull(trim(split(value#141, \\s+, 2)[0], None)))\n",
      "                        +- FileScan text [value#141] Batched: false, DataFilters: [NOT (trim(split(value#141, \\s+, 2)[0], None) = ), isnotnull(trim(split(value#141, \\s+, 2)[0], No..., Format: Text, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/MO_c..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      "\n",
      "\n",
      "Execution time: 5.713666677474976 seconds"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "result_merge = (\n",
    "    mo_counts\n",
    "    .hint(\"merge\")\n",
    "    .join(\n",
    "        mo_dict_df.hint(\"merge\"),\n",
    "        on=\"MO_CODE\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .orderBy(desc(\"count\"))\n",
    ")\n",
    "\n",
    "result_merge.show(10, truncate=False)\n",
    "result_merge.explain()\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30f4533e-6a49-406f-ba8f-3d7d7dcabbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17957c5d94a42758fba995d76740791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------------------------+\n",
      "|MO_CODE|count  |MO_DESC                    |\n",
      "+-------+-------+---------------------------+\n",
      "|0344   |1002900|Removes vict property      |\n",
      "|1822   |548422 |Stranger                   |\n",
      "|0416   |404773 |Hit-Hit w/ weapon          |\n",
      "|0329   |377536 |Vandalized                 |\n",
      "|0913   |278618 |Victim knew Suspect        |\n",
      "|2000   |256188 |Domestic violence          |\n",
      "|1300   |219082 |Vehicle involved           |\n",
      "|0400   |213165 |Force used                 |\n",
      "|1402   |177470 |Evidence Booked (any crime)|\n",
      "|1609   |131229 |Smashed                    |\n",
      "+-------+-------+---------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [count#615L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(count#615L DESC NULLS LAST, 1000), ENSURE_REQUIREMENTS, [plan_id=3031]\n",
      "      +- Project [MO_CODE#611, count#615L, MO_DESC#144]\n",
      "         +- ShuffledHashJoin [MO_CODE#611], [MO_CODE#143], LeftOuter, BuildRight\n",
      "            :- HashAggregate(keys=[MO_CODE#611], functions=[count(1)], schema specialized)\n",
      "            :  +- Exchange hashpartitioning(MO_CODE#611, 1000), ENSURE_REQUIREMENTS, [plan_id=3023]\n",
      "            :     +- HashAggregate(keys=[MO_CODE#611], functions=[partial_count(1)], schema specialized)\n",
      "            :        +- Filter NOT (MO_CODE#611 = )\n",
      "            :           +- Generate explode(split(trim(Mocodes#10, None), \\s+, -1)), false, [MO_CODE#611]\n",
      "            :              +- Union\n",
      "            :                 :- Filter isnotnull(Mocodes#10)\n",
      "            :                 :  +- FileScan csv [Mocodes#10] Batched: false, DataFilters: [isnotnull(Mocodes#10)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(Mocodes)], ReadSchema: struct<Mocodes:string>\n",
      "            :                 +- Filter isnotnull(Mocodes#73)\n",
      "            :                    +- FileScan csv [Mocodes#73] Batched: false, DataFilters: [isnotnull(Mocodes#73)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(Mocodes)], ReadSchema: struct<Mocodes:string>\n",
      "            +- Exchange hashpartitioning(MO_CODE#143, 1000), ENSURE_REQUIREMENTS, [plan_id=3027]\n",
      "               +- Project [trim(split(value#141, \\s+, 2)[0], None) AS MO_CODE#143, trim(split(value#141, \\s+, 2)[1], None) AS MO_DESC#144]\n",
      "                  +- Filter (NOT (trim(split(value#141, \\s+, 2)[0], None) = ) AND isnotnull(trim(split(value#141, \\s+, 2)[0], None)))\n",
      "                     +- FileScan text [value#141] Batched: false, DataFilters: [NOT (trim(split(value#141, \\s+, 2)[0], None) = ), isnotnull(trim(split(value#141, \\s+, 2)[0], No..., Format: Text, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/MO_c..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      "\n",
      "\n",
      "Execution time: 5.217807769775391 seconds"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "result_shuffle_hash = (\n",
    "    mo_counts\n",
    "    .hint(\"shuffle_hash\")\n",
    "    .join(\n",
    "        mo_dict_df.hint(\"shuffle_hash\"),\n",
    "        on=\"MO_CODE\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .orderBy(desc(\"count\"))\n",
    ")\n",
    "\n",
    "result_shuffle_hash.show(10, truncate=False)\n",
    "result_shuffle_hash.explain()\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end - start, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dec4b19-6661-4f6d-a7ed-92aac4bea1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f857ce9de94188b7f9c50960837fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------------------------+\n",
      "|MO_CODE|count  |MO_DESC                    |\n",
      "+-------+-------+---------------------------+\n",
      "|0344   |1002900|Removes vict property      |\n",
      "|1822   |548422 |Stranger                   |\n",
      "|0416   |404773 |Hit-Hit w/ weapon          |\n",
      "|0329   |377536 |Vandalized                 |\n",
      "|0913   |278618 |Victim knew Suspect        |\n",
      "|2000   |256188 |Domestic violence          |\n",
      "|1300   |219082 |Vehicle involved           |\n",
      "|0400   |213165 |Force used                 |\n",
      "|1402   |177470 |Evidence Booked (any crime)|\n",
      "|1609   |131229 |Smashed                    |\n",
      "+-------+-------+---------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [count#615L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(count#615L DESC NULLS LAST, 1000), ENSURE_REQUIREMENTS, [plan_id=3332]\n",
      "      +- Project [MO_CODE#611, count#615L, MO_DESC#144]\n",
      "         +- BroadcastHashJoin [MO_CODE#611], [MO_CODE#143], LeftOuter, BuildRight, false\n",
      "            :- HashAggregate(keys=[MO_CODE#611], functions=[count(1)], schema specialized)\n",
      "            :  +- Exchange hashpartitioning(MO_CODE#611, 1000), ENSURE_REQUIREMENTS, [plan_id=3325]\n",
      "            :     +- HashAggregate(keys=[MO_CODE#611], functions=[partial_count(1)], schema specialized)\n",
      "            :        +- Filter NOT (MO_CODE#611 = )\n",
      "            :           +- Generate explode(split(trim(Mocodes#10, None), \\s+, -1)), false, [MO_CODE#611]\n",
      "            :              +- Union\n",
      "            :                 :- Filter isnotnull(Mocodes#10)\n",
      "            :                 :  +- FileScan csv [Mocodes#10] Batched: false, DataFilters: [isnotnull(Mocodes#10)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(Mocodes)], ReadSchema: struct<Mocodes:string>\n",
      "            :                 +- Filter isnotnull(Mocodes#73)\n",
      "            :                    +- FileScan csv [Mocodes#73] Batched: false, DataFilters: [isnotnull(Mocodes#73)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(Mocodes)], ReadSchema: struct<Mocodes:string>\n",
      "            +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=3328]\n",
      "               +- Project [trim(split(value#141, \\s+, 2)[0], None) AS MO_CODE#143, trim(split(value#141, \\s+, 2)[1], None) AS MO_DESC#144]\n",
      "                  +- Filter (NOT (trim(split(value#141, \\s+, 2)[0], None) = ) AND isnotnull(trim(split(value#141, \\s+, 2)[0], None)))\n",
      "                     +- FileScan text [value#141] Batched: false, DataFilters: [NOT (trim(split(value#141, \\s+, 2)[0], None) = ), isnotnull(trim(split(value#141, \\s+, 2)[0], No..., Format: Text, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/MO_c..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      "\n",
      "\n",
      "Execution time: 2.606409788131714 seconds"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "result_shuffle_repl_nl = (\n",
    "    mo_counts\n",
    "    .hint(\"shuffle_replicate_nl\")\n",
    "    .join(\n",
    "        mo_dict_df.hint(\"shuffle_replicate_nl\"),\n",
    "        on=\"MO_CODE\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .orderBy(desc(\"count\"))\n",
    ")\n",
    "\n",
    "result_shuffle_repl_nl.show(10, truncate=False)\n",
    "result_shuffle_repl_nl.explain()\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end - start, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2f902a-7c59-480e-8994-1cc06712535d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
