{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31d0d797-6b27-45f9-8611-2242f1338070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '4', 'spark.executor.memory': '2g', 'spark.executor.cores': '1'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>597</td><td>application_1765289937462_0590</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0590/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-207.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0590_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>617</td><td>application_1765289937462_0610</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0610/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-207.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0610_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>618</td><td>application_1765289937462_0611</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0611/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-115.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0611_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>620</td><td>application_1765289937462_0613</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0613/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-213.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0613_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>624</td><td>application_1765289937462_0617</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0617/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-131.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0617_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>629</td><td>application_1765289937462_0622</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0622/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-48.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0622_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>632</td><td>application_1765289937462_0625</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0625/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-55.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0625_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>637</td><td>application_1765289937462_0630</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0630/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-250.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0630_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>642</td><td>application_1765289937462_0635</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0635/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-115.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0635_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>649</td><td>application_1765289937462_0642</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0642/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-141.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0642_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>651</td><td>application_1765289937462_0644</td><td>pyspark</td><td>starting</td><td></td><td></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\":{\n",
    "        \"spark.executor.instances\": \"4\",\n",
    "        \"spark.executor.memory\": \"2g\",\n",
    "        \"spark.executor.cores\": \"1\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36d5d933-f0dc-44b0-ae4e-cd3890a23eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>652</td><td>application_1765289937462_0645</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_0645/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-55.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_0645_01_000002/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "120127b722124aca9ac14dd65d9e9c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e00aa98bbc45a7bf90486b75212d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructField, StructType, IntegerType, FloatType, StringType\n",
    "from pyspark.sql.functions import col, split, explode, trim, desc  #import needed functions\n",
    "import time\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"DF query 3 execution\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "crime_schema = StructType([\n",
    "        StructField(\"DR_NO\", StringType()),\n",
    "        StructField(\"Date Rptd\", StringType()),\n",
    "        StructField(\"DATE OCC\", StringType()),\n",
    "        StructField(\"TIME OCC\", StringType()),\n",
    "        StructField(\"AREA\", StringType()),\n",
    "        StructField(\"AREA ΝΑΜΕ\", StringType()),\n",
    "        StructField(\"Rpt Dist No\", StringType()),\n",
    "        StructField(\"Part 1-2\", StringType()),\n",
    "        StructField(\"Crm Cd\", StringType()),\n",
    "        StructField(\"Crm Cd Desc\", StringType()),\n",
    "        StructField(\"Mocodes\", StringType()),\n",
    "        StructField(\"Vict Age\", IntegerType()),\n",
    "        StructField(\"Vict Sex\", StringType()),\n",
    "        StructField(\"Vict Descent\", StringType()),\n",
    "        StructField(\"Premis Cd\", StringType()),\n",
    "        StructField(\"Premis Desc\", StringType()),\n",
    "        StructField(\"Weapon Used Cd\", StringType()),\n",
    "        StructField(\"Weapon Desc\", StringType()),\n",
    "        StructField(\"Status\", StringType()),\n",
    "        StructField(\"Status Desc\", StringType()),\n",
    "        StructField(\"Crm Cd 1\", StringType()),\n",
    "        StructField(\"Crm Cd 2\", StringType()),\n",
    "        StructField(\"Crm Cd 3\", StringType()),\n",
    "        StructField(\"Crm Cd 4\", StringType()),\n",
    "        StructField(\"LOCATION\", StringType()),\n",
    "        StructField(\"Cross Street\", StringType()),\n",
    "        #StructField(\"LAT\", DoubleType()),\n",
    "        #StructField(\"LON\", DoubleType()),\n",
    "    ])\n",
    "\n",
    "crime_df1 = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv\", \\\n",
    "    header=False, \\\n",
    "    schema=crime_schema)\n",
    "\n",
    "crime_df2 = spark.read.csv(\"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\", \\\n",
    "    header=False, \\\n",
    "    schema=crime_schema)\n",
    "\n",
    "# make a single dataframe for crime data from 2010 to present\n",
    "crime_df = crime_df1.union(crime_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d83122be-6271-4740-ab56-3ce6fae4e26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e099075bec46adb48c38abaf75ec5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|MO_CODE|count|\n",
      "+-------+-----+\n",
      "|0543   |221  |\n",
      "|1512   |41   |\n",
      "|0851   |157  |\n",
      "|0401   |13049|\n",
      "|1280   |29   |\n",
      "|0201   |608  |\n",
      "|1008   |1071 |\n",
      "|0371   |15199|\n",
      "|0385   |41926|\n",
      "|0908   |1837 |\n",
      "+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "+-------+-------------------+\n",
      "|MO_CODE|MO_DESC            |\n",
      "+-------+-------------------+\n",
      "|0100   |Suspect Impersonate|\n",
      "|0101   |Aid victim         |\n",
      "|0102   |Blind              |\n",
      "|0103   |Physically disabled|\n",
      "|0104   |Customer           |\n",
      "|0105   |Delivery           |\n",
      "|0106   |Doctor             |\n",
      "|0107   |God                |\n",
      "|0108   |Infirm             |\n",
      "|0109   |Inspector          |\n",
      "+-------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Execution time: 13.864091634750366 seconds\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[MO_CODE#149], functions=[count(1)], schema specialized)\n",
      "   +- Exchange hashpartitioning(MO_CODE#149, 1000), ENSURE_REQUIREMENTS, [plan_id=173]\n",
      "      +- HashAggregate(keys=[MO_CODE#149], functions=[partial_count(1)], schema specialized)\n",
      "         +- Filter NOT (MO_CODE#149 = )\n",
      "            +- Generate explode(split(trim(Mocodes#10, None), \\s+, -1)), false, [MO_CODE#149]\n",
      "               +- Union\n",
      "                  :- Filter isnotnull(Mocodes#10)\n",
      "                  :  +- FileScan csv [Mocodes#10] Batched: false, DataFilters: [isnotnull(Mocodes#10)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(Mocodes)], ReadSchema: struct<Mocodes:string>\n",
      "                  +- Filter isnotnull(Mocodes#73)\n",
      "                     +- FileScan csv [Mocodes#73] Batched: false, DataFilters: [isnotnull(Mocodes#73)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(Mocodes)], ReadSchema: struct<Mocodes:string>\n",
      "\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Project [trim(split(value#141, \\s+, 2)[0], None) AS MO_CODE#143, trim(split(value#141, \\s+, 2)[1], None) AS MO_DESC#144]\n",
      "+- FileScan text [value#141] Batched: false, DataFilters: [], Format: Text, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/MO_c..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>"
     ]
    }
   ],
   "source": [
    "# raw text file: one line per code\n",
    "raw_mo = spark.read.text(\n",
    "    \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/MO_codes.txt\"\n",
    ")\n",
    "\n",
    "# assuming: \"<code> <spaces or tab> <description...>\"\n",
    "mo_dict_df = (\n",
    "    raw_mo\n",
    "    .select(\n",
    "        trim(split(col(\"value\"), r\"\\s+\", 2).getItem(0)).alias(\"MO_CODE\"),\n",
    "        trim(split(col(\"value\"), r\"\\s+\", 2).getItem(1)).alias(\"MO_DESC\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Keep rows with non-null Mocodes\n",
    "mocodes_exploded = (\n",
    "    crime_df\n",
    "    .filter(col(\"Mocodes\").isNotNull())\n",
    "    .select(\n",
    "        explode(\n",
    "            split(trim(col(\"Mocodes\")), r\"\\s+\")  # split on 1+ spaces\n",
    "        ).alias(\"MO_CODE\")\n",
    "    )\n",
    "    .filter(col(\"MO_CODE\") != \"\")  # drop empty pieces\n",
    ")\n",
    "\n",
    "mo_counts = (\n",
    "    mocodes_exploded\n",
    "    .groupBy(\"MO_CODE\")\n",
    "    .count()\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "mo_counts.show(10, truncate=False)\n",
    "mo_dict_df.show(10, truncate=False)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end - start, \"seconds\")\n",
    "\n",
    "mo_counts.explain()\n",
    "mo_dict_df.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fbd36f0-9647-49cb-b3b0-3ec4d0f581b9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df85cb5304a94ab48f917d22f01f743a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------------------------+\n",
      "|MO_CODE|count  |MO_DESC                    |\n",
      "+-------+-------+---------------------------+\n",
      "|0344   |1002900|Removes vict property      |\n",
      "|1822   |548422 |Stranger                   |\n",
      "|0416   |404773 |Hit-Hit w/ weapon          |\n",
      "|0329   |377536 |Vandalized                 |\n",
      "|0913   |278618 |Victim knew Suspect        |\n",
      "|2000   |256188 |Domestic violence          |\n",
      "|1300   |219082 |Vehicle involved           |\n",
      "|0400   |213165 |Force used                 |\n",
      "|1402   |177470 |Evidence Booked (any crime)|\n",
      "|1609   |131229 |Smashed                    |\n",
      "+-------+-------+---------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Execution time: 5.888071298599243 seconds\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [count#153L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(count#153L DESC NULLS LAST, 1000), ENSURE_REQUIREMENTS, [plan_id=469]\n",
      "      +- Project [MO_CODE#149, count#153L, MO_DESC#144]\n",
      "         +- BroadcastHashJoin [MO_CODE#149], [MO_CODE#143], LeftOuter, BuildRight, false\n",
      "            :- HashAggregate(keys=[MO_CODE#149], functions=[count(1)], schema specialized)\n",
      "            :  +- Exchange hashpartitioning(MO_CODE#149, 1000), ENSURE_REQUIREMENTS, [plan_id=462]\n",
      "            :     +- HashAggregate(keys=[MO_CODE#149], functions=[partial_count(1)], schema specialized)\n",
      "            :        +- Filter NOT (MO_CODE#149 = )\n",
      "            :           +- Generate explode(split(trim(Mocodes#10, None), \\s+, -1)), false, [MO_CODE#149]\n",
      "            :              +- Union\n",
      "            :                 :- Filter isnotnull(Mocodes#10)\n",
      "            :                 :  +- FileScan csv [Mocodes#10] Batched: false, DataFilters: [isnotnull(Mocodes#10)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(Mocodes)], ReadSchema: struct<Mocodes:string>\n",
      "            :                 +- Filter isnotnull(Mocodes#73)\n",
      "            :                    +- FileScan csv [Mocodes#73] Batched: false, DataFilters: [isnotnull(Mocodes#73)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(Mocodes)], ReadSchema: struct<Mocodes:string>\n",
      "            +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=465]\n",
      "               +- Project [trim(split(value#141, \\s+, 2)[0], None) AS MO_CODE#143, trim(split(value#141, \\s+, 2)[1], None) AS MO_DESC#144]\n",
      "                  +- Filter (NOT (trim(split(value#141, \\s+, 2)[0], None) = ) AND isnotnull(trim(split(value#141, \\s+, 2)[0], None)))\n",
      "                     +- FileScan text [value#141] Batched: false, DataFilters: [NOT (trim(split(value#141, \\s+, 2)[0], None) = ), isnotnull(trim(split(value#141, \\s+, 2)[0], No..., Format: Text, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/MO_c..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>"
     ]
    }
   ],
   "source": [
    "\n",
    "result = (\n",
    "    mo_counts\n",
    "    .join(mo_dict_df, on=\"MO_CODE\", how=\"left\")\n",
    "    .orderBy(desc(\"count\"))\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "result.show(10, truncate=False)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end - start, \"seconds\")\n",
    "\n",
    "result.explain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9eeea34a-5ef0-4ccf-ada5-22a44aa557e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c4d8dfeee14e13975d664a8183a427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------------------------+\n",
      "|MO_CODE|count  |MO_DESC                    |\n",
      "+-------+-------+---------------------------+\n",
      "|0344   |1002900|Removes vict property      |\n",
      "|1822   |548422 |Stranger                   |\n",
      "|0416   |404773 |Hit-Hit w/ weapon          |\n",
      "|0329   |377536 |Vandalized                 |\n",
      "|0913   |278618 |Victim knew Suspect        |\n",
      "|2000   |256188 |Domestic violence          |\n",
      "|1300   |219082 |Vehicle involved           |\n",
      "|0400   |213165 |Force used                 |\n",
      "|1402   |177470 |Evidence Booked (any crime)|\n",
      "|1609   |131229 |Smashed                    |\n",
      "+-------+-------+---------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Execution time: 2.570488929748535 seconds\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [count#153L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(count#153L DESC NULLS LAST, 1000), ENSURE_REQUIREMENTS, [plan_id=769]\n",
      "      +- Project [MO_CODE#149, count#153L, MO_DESC#144]\n",
      "         +- BroadcastHashJoin [MO_CODE#149], [MO_CODE#143], LeftOuter, BuildRight, false\n",
      "            :- HashAggregate(keys=[MO_CODE#149], functions=[count(1)], schema specialized)\n",
      "            :  +- Exchange hashpartitioning(MO_CODE#149, 1000), ENSURE_REQUIREMENTS, [plan_id=762]\n",
      "            :     +- HashAggregate(keys=[MO_CODE#149], functions=[partial_count(1)], schema specialized)\n",
      "            :        +- Filter NOT (MO_CODE#149 = )\n",
      "            :           +- Generate explode(split(trim(Mocodes#10, None), \\s+, -1)), false, [MO_CODE#149]\n",
      "            :              +- Union\n",
      "            :                 :- Filter isnotnull(Mocodes#10)\n",
      "            :                 :  +- FileScan csv [Mocodes#10] Batched: false, DataFilters: [isnotnull(Mocodes#10)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(Mocodes)], ReadSchema: struct<Mocodes:string>\n",
      "            :                 +- Filter isnotnull(Mocodes#73)\n",
      "            :                    +- FileScan csv [Mocodes#73] Batched: false, DataFilters: [isnotnull(Mocodes#73)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(Mocodes)], ReadSchema: struct<Mocodes:string>\n",
      "            +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=765]\n",
      "               +- Project [trim(split(value#141, \\s+, 2)[0], None) AS MO_CODE#143, trim(split(value#141, \\s+, 2)[1], None) AS MO_DESC#144]\n",
      "                  +- Filter (NOT (trim(split(value#141, \\s+, 2)[0], None) = ) AND isnotnull(trim(split(value#141, \\s+, 2)[0], None)))\n",
      "                     +- FileScan text [value#141] Batched: false, DataFilters: [NOT (trim(split(value#141, \\s+, 2)[0], None) = ), isnotnull(trim(split(value#141, \\s+, 2)[0], No..., Format: Text, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/MO_c..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>"
     ]
    }
   ],
   "source": [
    "# Note that hints are advisory (Spark may ignore them in pathological cases) and AQE can override them unless disabled.\n",
    "result_broadcast = (\n",
    "    mo_counts\n",
    "    .join(\n",
    "        mo_dict_df.hint(\"broadcast\"),\n",
    "        on=\"MO_CODE\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .orderBy(desc(\"count\"))\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "result_broadcast.show(10, truncate=False)\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end - start, \"seconds\")\n",
    "\n",
    "result_broadcast.explain()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a1a84cc-897a-4607-a268-e63c76444594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7b1283c7434162a95569adddddbeee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------------------------+\n",
      "|MO_CODE|count  |MO_DESC                    |\n",
      "+-------+-------+---------------------------+\n",
      "|0344   |1002900|Removes vict property      |\n",
      "|1822   |548422 |Stranger                   |\n",
      "|0416   |404773 |Hit-Hit w/ weapon          |\n",
      "|0329   |377536 |Vandalized                 |\n",
      "|0913   |278618 |Victim knew Suspect        |\n",
      "|2000   |256188 |Domestic violence          |\n",
      "|1300   |219082 |Vehicle involved           |\n",
      "|0400   |213165 |Force used                 |\n",
      "|1402   |177470 |Evidence Booked (any crime)|\n",
      "|1609   |131229 |Smashed                    |\n",
      "+-------+-------+---------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Execution time: 3.2403318881988525 seconds\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [count#153L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(count#153L DESC NULLS LAST, 1000), ENSURE_REQUIREMENTS, [plan_id=1123]\n",
      "      +- Project [MO_CODE#149, count#153L, MO_DESC#144]\n",
      "         +- SortMergeJoin [MO_CODE#149], [MO_CODE#143], LeftOuter\n",
      "            :- Sort [MO_CODE#149 ASC NULLS FIRST], false, 0\n",
      "            :  +- HashAggregate(keys=[MO_CODE#149], functions=[count(1)], schema specialized)\n",
      "            :     +- Exchange hashpartitioning(MO_CODE#149, 1000), ENSURE_REQUIREMENTS, [plan_id=1113]\n",
      "            :        +- HashAggregate(keys=[MO_CODE#149], functions=[partial_count(1)], schema specialized)\n",
      "            :           +- Filter NOT (MO_CODE#149 = )\n",
      "            :              +- Generate explode(split(trim(Mocodes#10, None), \\s+, -1)), false, [MO_CODE#149]\n",
      "            :                 +- Union\n",
      "            :                    :- Filter isnotnull(Mocodes#10)\n",
      "            :                    :  +- FileScan csv [Mocodes#10] Batched: false, DataFilters: [isnotnull(Mocodes#10)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(Mocodes)], ReadSchema: struct<Mocodes:string>\n",
      "            :                    +- Filter isnotnull(Mocodes#73)\n",
      "            :                       +- FileScan csv [Mocodes#73] Batched: false, DataFilters: [isnotnull(Mocodes#73)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(Mocodes)], ReadSchema: struct<Mocodes:string>\n",
      "            +- Sort [MO_CODE#143 ASC NULLS FIRST], false, 0\n",
      "               +- Exchange hashpartitioning(MO_CODE#143, 1000), ENSURE_REQUIREMENTS, [plan_id=1117]\n",
      "                  +- Project [trim(split(value#141, \\s+, 2)[0], None) AS MO_CODE#143, trim(split(value#141, \\s+, 2)[1], None) AS MO_DESC#144]\n",
      "                     +- Filter (NOT (trim(split(value#141, \\s+, 2)[0], None) = ) AND isnotnull(trim(split(value#141, \\s+, 2)[0], None)))\n",
      "                        +- FileScan text [value#141] Batched: false, DataFilters: [NOT (trim(split(value#141, \\s+, 2)[0], None) = ), isnotnull(trim(split(value#141, \\s+, 2)[0], No..., Format: Text, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/MO_c..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>"
     ]
    }
   ],
   "source": [
    "result_merge = (\n",
    "    mo_counts\n",
    "    .hint(\"merge\")\n",
    "    .join(\n",
    "        mo_dict_df.hint(\"merge\"),\n",
    "        on=\"MO_CODE\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .orderBy(desc(\"count\"))\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "result_merge.show(10, truncate=False)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end - start, \"seconds\")\n",
    "\n",
    "result_merge.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30f4533e-6a49-406f-ba8f-3d7d7dcabbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50140b1689cc458a8227cc45988383a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------------------------+\n",
      "|MO_CODE|count  |MO_DESC                    |\n",
      "+-------+-------+---------------------------+\n",
      "|0344   |1002900|Removes vict property      |\n",
      "|1822   |548422 |Stranger                   |\n",
      "|0416   |404773 |Hit-Hit w/ weapon          |\n",
      "|0329   |377536 |Vandalized                 |\n",
      "|0913   |278618 |Victim knew Suspect        |\n",
      "|2000   |256188 |Domestic violence          |\n",
      "|1300   |219082 |Vehicle involved           |\n",
      "|0400   |213165 |Force used                 |\n",
      "|1402   |177470 |Evidence Booked (any crime)|\n",
      "|1609   |131229 |Smashed                    |\n",
      "+-------+-------+---------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Execution time: 2.47884464263916 seconds\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [count#153L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(count#153L DESC NULLS LAST, 1000), ENSURE_REQUIREMENTS, [plan_id=1448]\n",
      "      +- Project [MO_CODE#149, count#153L, MO_DESC#144]\n",
      "         +- ShuffledHashJoin [MO_CODE#149], [MO_CODE#143], LeftOuter, BuildRight\n",
      "            :- HashAggregate(keys=[MO_CODE#149], functions=[count(1)], schema specialized)\n",
      "            :  +- Exchange hashpartitioning(MO_CODE#149, 1000), ENSURE_REQUIREMENTS, [plan_id=1440]\n",
      "            :     +- HashAggregate(keys=[MO_CODE#149], functions=[partial_count(1)], schema specialized)\n",
      "            :        +- Filter NOT (MO_CODE#149 = )\n",
      "            :           +- Generate explode(split(trim(Mocodes#10, None), \\s+, -1)), false, [MO_CODE#149]\n",
      "            :              +- Union\n",
      "            :                 :- Filter isnotnull(Mocodes#10)\n",
      "            :                 :  +- FileScan csv [Mocodes#10] Batched: false, DataFilters: [isnotnull(Mocodes#10)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(Mocodes)], ReadSchema: struct<Mocodes:string>\n",
      "            :                 +- Filter isnotnull(Mocodes#73)\n",
      "            :                    +- FileScan csv [Mocodes#73] Batched: false, DataFilters: [isnotnull(Mocodes#73)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(Mocodes)], ReadSchema: struct<Mocodes:string>\n",
      "            +- Exchange hashpartitioning(MO_CODE#143, 1000), ENSURE_REQUIREMENTS, [plan_id=1444]\n",
      "               +- Project [trim(split(value#141, \\s+, 2)[0], None) AS MO_CODE#143, trim(split(value#141, \\s+, 2)[1], None) AS MO_DESC#144]\n",
      "                  +- Filter (NOT (trim(split(value#141, \\s+, 2)[0], None) = ) AND isnotnull(trim(split(value#141, \\s+, 2)[0], None)))\n",
      "                     +- FileScan text [value#141] Batched: false, DataFilters: [NOT (trim(split(value#141, \\s+, 2)[0], None) = ), isnotnull(trim(split(value#141, \\s+, 2)[0], No..., Format: Text, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/MO_c..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>"
     ]
    }
   ],
   "source": [
    "result_shuffle_hash = (\n",
    "    mo_counts\n",
    "    .hint(\"shuffle_hash\")\n",
    "    .join(\n",
    "        mo_dict_df.hint(\"shuffle_hash\"),\n",
    "        on=\"MO_CODE\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .orderBy(desc(\"count\"))\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "result_shuffle_hash.show(10, truncate=False)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end - start, \"seconds\")\n",
    "\n",
    "result_shuffle_hash.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dec4b19-6661-4f6d-a7ed-92aac4bea1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "574964f34fd34a7d9e1549b129c562c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+---------------------------+\n",
      "|MO_CODE|count  |MO_DESC                    |\n",
      "+-------+-------+---------------------------+\n",
      "|0344   |1002900|Removes vict property      |\n",
      "|1822   |548422 |Stranger                   |\n",
      "|0416   |404773 |Hit-Hit w/ weapon          |\n",
      "|0329   |377536 |Vandalized                 |\n",
      "|0913   |278618 |Victim knew Suspect        |\n",
      "|2000   |256188 |Domestic violence          |\n",
      "|1300   |219082 |Vehicle involved           |\n",
      "|0400   |213165 |Force used                 |\n",
      "|1402   |177470 |Evidence Booked (any crime)|\n",
      "|1609   |131229 |Smashed                    |\n",
      "+-------+-------+---------------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Execution time: 2.155559778213501 seconds\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [count#153L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(count#153L DESC NULLS LAST, 1000), ENSURE_REQUIREMENTS, [plan_id=1749]\n",
      "      +- Project [MO_CODE#149, count#153L, MO_DESC#144]\n",
      "         +- BroadcastHashJoin [MO_CODE#149], [MO_CODE#143], LeftOuter, BuildRight, false\n",
      "            :- HashAggregate(keys=[MO_CODE#149], functions=[count(1)], schema specialized)\n",
      "            :  +- Exchange hashpartitioning(MO_CODE#149, 1000), ENSURE_REQUIREMENTS, [plan_id=1742]\n",
      "            :     +- HashAggregate(keys=[MO_CODE#149], functions=[partial_count(1)], schema specialized)\n",
      "            :        +- Filter NOT (MO_CODE#149 = )\n",
      "            :           +- Generate explode(split(trim(Mocodes#10, None), \\s+, -1)), false, [MO_CODE#149]\n",
      "            :              +- Union\n",
      "            :                 :- Filter isnotnull(Mocodes#10)\n",
      "            :                 :  +- FileScan csv [Mocodes#10] Batched: false, DataFilters: [isnotnull(Mocodes#10)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(Mocodes)], ReadSchema: struct<Mocodes:string>\n",
      "            :                 +- Filter isnotnull(Mocodes#73)\n",
      "            :                    +- FileScan csv [Mocodes#73] Batched: false, DataFilters: [isnotnull(Mocodes#73)], Format: CSV, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(Mocodes)], ReadSchema: struct<Mocodes:string>\n",
      "            +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=1745]\n",
      "               +- Project [trim(split(value#141, \\s+, 2)[0], None) AS MO_CODE#143, trim(split(value#141, \\s+, 2)[1], None) AS MO_DESC#144]\n",
      "                  +- Filter (NOT (trim(split(value#141, \\s+, 2)[0], None) = ) AND isnotnull(trim(split(value#141, \\s+, 2)[0], None)))\n",
      "                     +- FileScan text [value#141] Batched: false, DataFilters: [NOT (trim(split(value#141, \\s+, 2)[0], None) = ), isnotnull(trim(split(value#141, \\s+, 2)[0], No..., Format: Text, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/MO_c..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>"
     ]
    }
   ],
   "source": [
    "result_shuffle_repl_nl = (\n",
    "    mo_counts\n",
    "    .hint(\"shuffle_replicate_nl\")\n",
    "    .join(\n",
    "        mo_dict_df.hint(\"shuffle_replicate_nl\"),\n",
    "        on=\"MO_CODE\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .orderBy(desc(\"count\"))\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "result_shuffle_repl_nl.show(10, truncate=False)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end - start, \"seconds\")\n",
    "\n",
    "result_shuffle_repl_nl.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2f902a-7c59-480e-8994-1cc06712535d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
